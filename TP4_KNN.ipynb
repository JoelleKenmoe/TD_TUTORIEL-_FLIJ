{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df963ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATRICULES ET NOMS DES MEMBRES DU GROUPE\n",
    "\n",
    "# 19M2291  NOUBI-SI  KUISSEU  INES GAETAN\n",
    "# 19M2247  MEFOHO  LAURA\n",
    "# 18T2418   HAPI  KAMGANG  FRANCK\n",
    "# 19M2490  KEMTCHOUANG  KENMOE  JOELLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2a4dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificateur de courrier indésirable avec KNN - From Scratch (Python)\n",
    "# Un guide étape par étape pour la mise en œuvre de l'algorithme KNN pour classer les spams à l'aide de Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN (K-Nearest Neighbours) est l'un des algorithmes d'apprentissage supervisé les plus simples.\n",
    "Cependant, contrairement aux algorithmes d'apprentissage supervisés traditionnels, tels que l'algorithme Multinomial Naive Bayes, \n",
    "KNN n'a pas d'étape de formation indépendante, puis une étape où les étiquettes des données de test sont prédites sur la base du modèle formé. \n",
    "Au lieu de cela, les caractéristiques de chaque élément de données de test sont comparées aux caractéristiques de chaque élément de données de formation en temps réel, \n",
    "puis les K éléments de données de formation les plus proches sont sélectionnés, \n",
    "et la classe la plus fréquente parmi eux est attribuée à l'élément de données de test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb461752",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dans le cadre de la classification des emails (spam ou ham), \n",
    "les caractéristiques à comparer sont les fréquences d'un mot dans chaque email.\n",
    "La distance euclidienne est utilisée pour déterminer la similarité entre deux e-mails ; \n",
    "plus la distance est petite, plus elle est similaire. \n",
    "La formule de distance euclidienne utilisée dans l'algorithme est la suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "![IMTPE3.png](attachment:IMTPE3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f314d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Une fois la distance euclidienne entre un e-mail de test et chaque e-mail d'entraînement calculée, les distances sont triées par ordre croissant (du plus proche au plus éloigné) et les K e-mails voisins les plus proches sont sélectionnés. Si la majorité est du spam, alors l'e-mail de test est étiqueté comme spam, sinon, il est étiqueté comme ham.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7eb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76936885",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31c2523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRAIRIE UTILISEES\n",
    "\n",
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21befcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHARGEMENT DES DONEES\n",
    "\n",
    " # Load ham email\n",
    "    for file_path in ham_files_location:\n",
    "        f = open(\"dataset/ham/\" + file_path, \"r\")\n",
    "        text = str(f.read())\n",
    "        data.append([text, \"ham\"])\n",
    "    \n",
    "    # Load spam email\n",
    "    for file_path in spam_files_location:\n",
    "        f = open(\"dataset/spam/\" + file_path, \"r\")\n",
    "        text = str(f.read())\n",
    "        data.append([text, \"spam\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "    \n",
    "    print(\"flag 1: loaded data\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    " Data Pre-processing\n",
    "\n",
    "# Preprocessing data: noise removaldef preprocess_data(data):\n",
    "    print(\"Preprocessing data...\")\n",
    "    \n",
    "    punc = string.punctuation           # Punctuation list\n",
    "    sw = stopwords.words('english')     # Stopwords list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4841d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in data:\n",
    "        # enlever les ponctuations et les symboles\n",
    "        for item in punc:\n",
    "            record[0] = record[0].replace(item, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b45b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Lowercase all letters and remove stopwords \n",
    "        splittedWords = record[0].split()\n",
    "        newText = \"\"\n",
    "        for word in splittedWords:\n",
    "            if word not in sw:\n",
    "                word = word.lower()\n",
    "                newText = newText + \" \" + word          record[0] = newText\n",
    "        \n",
    "    print(\"flag 2: preprocessed data\")        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115deeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Splitting original dataset into training dataset and test datasetdef split_data(data):\n",
    "    print(\"Splitting data...\")\n",
    "    \n",
    "    features = data[:, 0]   # array containing all email text bodies\n",
    "    labels = data[:, 1]     # array containing corresponding labels\n",
    "    print(labels)\n",
    "    training_data, test_data, training_labels, test_labels =\\\n",
    "        train_test_split(features, labels, test_size = 0.27, random_state = 42)\n",
    "    \n",
    "    print(\"flag 3: splitted data\")\n",
    "    return training_data, test_data, training_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313f5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The KNN Algorithm\n",
    "\n",
    "get_count() function\n",
    "\n",
    "def get_count(text):\n",
    "    wordCounts = dict()\n",
    "    for word in text.split():\n",
    "        if word in wordCounts:\n",
    "            wordCounts[word] += 1\n",
    "        else:\n",
    "            wordCounts[word] = 1\n",
    "    \n",
    "    return wordCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55160ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#euclidean_difference() function\n",
    "\n",
    "def euclidean_difference(test_WordCounts, training_WordCounts):\n",
    "    total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6379ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in test_WordCounts:\n",
    "        if word in test_WordCounts and word in training_WordCounts:\n",
    "            total += (test_WordCounts[word] - training_WordCounts[word])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "  del training_WordCounts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d3db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "  else:\n",
    "            total += test_WordCounts[word]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15efee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "  return total**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bef3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_class() function\n",
    "\n",
    "def get_class(selected_Kvalues):\n",
    "    spam_count = 0\n",
    "    ham_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6f6be",
   "metadata": {},
   "outputs": [],
   "source": [
    " for value in selected_Kvalues:\n",
    "        if value[0] == \"spam\":\n",
    "            spam_count += 1\n",
    "        else:\n",
    "            ham_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    " if spam_count > ham_count:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier() function\n",
    "\n",
    "def knn_classifier(training_data, training_labels, test_data, K, tsize):\n",
    "    print(\"Running KNN Classifier...\")\n",
    "    \n",
    "    result = []\n",
    "    counter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113e2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # word counts for training email\n",
    "    training_WordCounts = [] \n",
    "    for training_text in training_data:\n",
    "            training_WordCounts.append(get_count(training_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d106c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_text in test_data:\n",
    "        similarity = [] # List of euclidean distances\n",
    "        test_WordCounts = get_count(test_text)  # word counts for test email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Getting euclidean difference \n",
    "        for index in range(len(training_data)):\n",
    "            euclidean_diff =\\\n",
    "                euclidean_difference(test_WordCounts, training_WordCounts[index])\n",
    "            similarity.append([training_labels[index], euclidean_diff])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc316ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Sort list in ascending order based on euclidean difference\n",
    "        similarity = sorted(similarity, key = lambda i:i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d0ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Select K nearest neighbours\n",
    "        selected_Kvalues = [] \n",
    "        for i in range(K):\n",
    "            selected_Kvalues.append(similarity[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495c2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Predicting the class of email\n",
    "        result.append(get_class(selected_Kvalues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74100b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    " return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main() function\n",
    "\n",
    "def main(K):\n",
    "    data = load_data()\n",
    "    data = preprocess_data(data)\n",
    "    training_data, test_data, training_labels, test_labels = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsize = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0902b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = knn_classifier(training_data, training_labels, test_data[:tsize], K, tsize) \n",
    "    accuracy = accuracy_score(test_labels[:tsize], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55495dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    print(\"training data size\\t: \" + str(len(training_data)))\n",
    "    print(\"test data size\\t\\t: \" + str(len(test_data)))\n",
    "    print(\"K value\\t\\t\\t\\t: \" + str(K))\n",
    "    print(\"Samples tested\\t\\t: \" + str(tsize))\n",
    "    print(\"% accuracy\\t\\t\\t: \" + str(accuracy * 100))\n",
    "    print(\"Number correct\\t\\t: \" + str(int(accuracy * tsize)))\n",
    "    print(\"Number wrong\\t\\t: \" + str(int((1 - accuracy) * tsize)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cd1b49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f94fd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb6e360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
